
import tensorflow as tf

print(f"TensorFlow version: {tf.__version__}")
gpus = tf.config.list_physical_devices('GPU')
print(f"GPUs detected: {len(gpus)}")

if gpus:
    try:
        for i, gpu in enumerate(gpus):
            print(f"  ‚Ü™ GPU {i}: {gpu.name}")
            tf.config.experimental.set_memory_growth(gpu, True)
        print(" Memory growth enabled for all available GPUs.")
    except RuntimeError as e:
        print(f" Error configuring GPU memory growth: {e}")
else:
    print(" No GPU devices found.")
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
import cv2
from tifffile import imread, TiffFile
from sklearn.model_selection import train_test_split
import tensorflow.keras.backend as K

# ---- CONFIG ----
image_dir = r"D:\Jyotsna_2025\vscode1\model_unet\archive\Training_Dataset\augmented_images6"
mask_dir  = r"D:\Jyotsna_2025\vscode1\model_unet\archive\Training_Dataset\augmented_masks6"

IMG_HEIGHT = 256
IMG_WIDTH = 256
BATCH_SIZE = 16
EPOCHS = 100
SEED = 42
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import backend as K
from tifffile import imread, TiffFile

# ------------------ LOSS & METRICS ------------------

def multiclass_dice_coef(y_true, y_pred, smooth=1e-6):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

def combined_loss(y_true, y_pred):
    y_pred = K.clip(y_pred, 1e-7, 1 - 1e-7)  # Prevent log(0)
    y_true = K.cast(y_true, dtype='float32')  # Ensure consistency
    cce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)
    dice_loss = 1 - multiclass_dice_coef(y_true, y_pred)
    return cce + dice_loss

# ------------------ LABEL REMAPPING & ONE-HOT ------------------

def remap_mask_labels(mask):
    """
    Convert mask values: 0 ‚Üí 0 (bg), 1 ‚Üí 1 (pomegranate), 4 ‚Üí 2 (date palm)
    """
    remapped = np.copy(mask)
    remapped[mask == 4] = 2
    return remapped

def one_hot_encode(mask, num_classes=3):
    h, w = mask.shape
    one_hot = np.zeros((h, w, num_classes), dtype=np.uint8)
    for c in range(num_classes):
        one_hot[:, :, c] = (mask == c).astype(np.uint8)
    return one_hot

# ------------------ FILE FILTERING & ID MATCHING ------------------

def is_valid_tiff_file(fname):
    ext = os.path.splitext(fname)[1].lower()
    return ext in ['.tif', '.tiff'] and not fname.lower().endswith(('.aux', '.aux.xml', '.xml', '.bak'))

def extract_id_and_ext(filename, prefix):
    name, ext = os.path.splitext(filename)
    core_id = name.replace(prefix, "")
    return core_id, ext

def is_truly_tiff(path):
    try:
        with TiffFile(path) as tif:
            _ = tif.pages[0]
        return True
    except Exception as e:
        print(f"Skipped unreadable: {path} | {e}")
        return False

# ------------------ MAIN VALIDATION PIPELINE ------------------


image_dir = r"D:\Jyotsna_Kartik_BITS_2025\vscode1\model_unet\archive\Training_Dataset\augmented_images6"
mask_dir  = r"D:\Jyotsna_Kartik_BITS_2025\vscode1\model_unet\archive\Training_Dataset\augmented_masks6"

image_files = [f for f in os.listdir(image_dir) if is_valid_tiff_file(f) and f.startswith("image_")]
mask_files  = [f for f in os.listdir(mask_dir)  if is_valid_tiff_file(f) and f.startswith("mask_")]


image_map = {extract_id_and_ext(f, "image_")[0]: f for f in image_files}
mask_map  = {extract_id_and_ext(f, "mask_")[0]: f for f in mask_files}


common_ids = sorted(list(set(image_map.keys()) & set(mask_map.keys())))
print(f"‚úÖ Matched image-mask ID pairs: {len(common_ids)}")

valid_ids = []
for id in common_ids:
    image_path = os.path.join(image_dir, f"image_{id}.tif")
    mask_path  = os.path.join(mask_dir,  f"mask_{id}.tif")

    if is_truly_tiff(image_path) and is_truly_tiff(mask_path):
        valid_ids.append(id)

print(f"Final usable image-mask pairs: {len(valid_ids)}")

if not valid_ids:
    raise ValueError("No usable TIFF pairs after final check!")

# ------------------ DEBUG: VISUALIZE MASK VALUES ------------------


debug_id = valid_ids[0]
mask_debug_path = os.path.join(mask_dir, f"mask_{debug_id}.tif")
mask = imread(mask_debug_path)
remapped = remap_mask_labels(mask)
one_hot = one_hot_encode(remapped, num_classes=3)

print(f"DEBUG for mask_{debug_id}:")
print(f"Original mask values: {np.unique(mask)}")
print(f"After remapping: {np.unique(remapped)}")
print(f"One-hot shape: {one_hot.shape} | Channels: {np.unique(np.argmax(one_hot, axis=-1))}")
from sklearn.model_selection import train_test_split

# ------------------ DATA SPLIT ------------------


X_train, X_val = train_test_split(valid_ids, test_size=0.2, random_state=SEED)
print(f"üìä Train IDs: {len(X_train)} | Val IDs: {len(X_val)}")

# ------------------ MULTICLASS DATA GENERATOR ------------------

import numpy as np
import os
import cv2
import tensorflow as tf
from tifffile import imread

class DataGenerator(tf.keras.utils.Sequence):
    def __init__(self, id_list, image_dir, mask_dir, batch_size, img_size, shuffle=True):
        self.id_list = id_list
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.batch_size = batch_size
        self.img_size = img_size  # (width, height)
        self.shuffle = shuffle
        self.on_epoch_end()

    def __len__(self):
        return int(np.ceil(len(self.id_list) / self.batch_size))

    def __getitem__(self, index):
        batch_ids = self.id_list[index * self.batch_size:(index + 1) * self.batch_size]
        images, masks = [], []
        for id in batch_ids:
            # --- Load image ---
            img_path = os.path.join(self.image_dir, f"image_{id}.tif")
            img = imread(img_path)

            if img.ndim == 2:
                img = np.stack([img] * 3, axis=-1)  # grayscale ‚Üí RGB
            img = cv2.resize(img, self.img_size)
            img = img.astype(np.float32)  #Already normalized externally in the provided dataset

            
            if np.isnan(img).any() or np.isinf(img).any():
                raise ValueError(f"‚ùå Invalid image data (NaN/Inf) in: {img_path}")

            # --- Load mask ---
            mask_path = os.path.join(self.mask_dir, f"mask_{id}.tif")
            mask = imread(mask_path)
            mask = cv2.resize(mask, self.img_size, interpolation=cv2.INTER_NEAREST)

            # Remap: 4 ‚Üí 2 so that labels are [0, 1, 2]
            remapped_mask = np.copy(mask)
            remapped_mask[mask == 4] = 2

            # One-hot encode: shape ‚Üí (H, W, 3)
            one_hot_mask = tf.keras.utils.to_categorical(remapped_mask, num_classes=3).astype(np.float32)

            # --- Append to batch ---
            images.append(img)
            masks.append(one_hot_mask)

        X = np.array(images, dtype=np.float32)
        Y = np.array(masks, dtype=np.float32)

        # Final batch integrity check
        if np.isnan(X).any() or np.isnan(Y).any() or np.isinf(X).any() or np.isinf(Y).any():
            raise ValueError(f" NaN or Inf detected in batch {index} | IDs: {batch_ids}")

        return X, Y

    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.id_list)
from tensorflow.keras import layers, models

def conv_block(inputs, filters):
    x = layers.Conv2D(filters, 3, padding="same", activation="relu")(inputs)
    x = layers.Conv2D(filters, 3, padding="same", activation="relu")(x)
    return x

def encoder_block(inputs, filters):
    x = conv_block(inputs, filters)
    p = layers.MaxPooling2D((2, 2))(x)
    return x, p

def decoder_block(inputs, skip, filters):
    x = layers.Conv2DTranspose(filters, (2, 2), strides=2, padding="same")(inputs)
    x = layers.Concatenate()([x, skip])
    x = conv_block(x, filters)
    return x

def build_unet(input_shape=(256, 256, 3), num_classes=3):
    inputs = layers.Input(shape=input_shape)

    # --- Encoder ---
    s1, p1 = encoder_block(inputs, 64)
    s2, p2 = encoder_block(p1, 128)
    s3, p3 = encoder_block(p2, 256)
    s4, p4 = encoder_block(p3, 512)

    # --- Bottleneck ---
    b = conv_block(p4, 1024)

    # --- Decoder ---
    d1 = decoder_block(b, s4, 512)
    d2 = decoder_block(d1, s3, 256)
    d3 = decoder_block(d2, s2, 128)
    d4 = decoder_block(d3, s1, 64)

    # --- Output layer for multiclass segmentation ---
    outputs = layers.Conv2D(num_classes, 1, padding="same", activation="softmax")(d4)

    return models.Model(inputs, outputs, name="U-Net")

# ---- COMPILE AND TRAIN (Multiclass Segmentation) ----

#  Use the updated DataGenerator, which includes:
# - mask remapping (4 ‚Üí 2)
# - one-hot encoding to 3 channels
train_gen = DataGenerator(X_train, image_dir, mask_dir, BATCH_SIZE, (IMG_WIDTH, IMG_HEIGHT))
val_gen   = DataGenerator(X_val,   image_dir, mask_dir, BATCH_SIZE, (IMG_WIDTH, IMG_HEIGHT))

#  Build U-Net with 3-class softmax output
model = build_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), num_classes=3)
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)

#  Use multiclass-compatible loss and dice metric
model.compile(
    optimizer=optimizer,
    loss=combined_loss,                    
    metrics=['accuracy', multiclass_dice_coef]
)

model.summary()

#  Callbacks
callbacks = [
    tf.keras.callbacks.ModelCheckpoint("best_unet_model_1/07/25.h5", save_best_only=True, verbose=1),
    tf.keras.callbacks.EarlyStopping(patience=25, restore_best_weights=True, verbose=1),
    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, verbose=1)
]

#  Train
history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=EPOCHS,
    callbacks=callbacks
)
# 1Ô∏è‚É£ Load the required components first
from tensorflow.keras.models import load_model
from tensorflow.keras.optimizers import Adam

# Redefine dice_coef since it's a custom metric
def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true_f = tf.keras.backend.flatten(y_true)
    y_pred_f = tf.keras.backend.flatten(y_pred)
    y_pred_f = tf.cast(y_pred_f > 0.5, tf.float32)
    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)

# 2Ô∏è‚É£ Load and compile the model
model = load_model("best_unet_model_1/07/25.h5", compile=False)
model.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy', dice_coef])

# 3Ô∏è‚É£ Evaluate on validation generator
loss, accuracy, dice = model.evaluate(val_gen, verbose=1)
print(f"\nFinal Evaluation:")
print(f"   ‚û§ Accuracy:       {accuracy:.4f}")
print(f"   ‚û§ Dice Coefficient: {dice:.4f}")
